# -*- coding: utf-8 -*-
"""edible_or_not

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ysnHDjoUzo8V7SQuLqvKSBbhsW21uuM5
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive/')
# %cd /gdrive

ls

cd /gdrive/MyDrive/edible_or_not

ls

"""# Importing Libraries"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
import warnings
warnings.filterwarnings("ignore")
import joblib

"""# Uploading Dataset"""

df_train=pd.read_csv('mushrooms.csv')
df_train.head()

df_train.info()

df_train.describe().style.background_gradient(axis=0,cmap = 'RdYlGn')

"""# EDA"""

df_train.isna().sum().sum()

df_train.columns

columns = df_train.columns
binary_cols = []
remain_cols=[]
for col in columns:
    if df_train[col].value_counts().shape[0] == 2:
        binary_cols.append(col)
    else:
      remain_cols.append(col)

binary_cols

sns.countplot("class", data=df_train)

sns.countplot("population", data=df_train)

capsurface_numeric = {'s':3,'y':2,'f':1,'g':0}
df_train.capsurface.replace(capsurface_numeric, inplace=True)

capcolor_numeric = {'n':9,'y':8,'w':7,'g':6,'e':5,'p':4,'b':3,'u':2,'c':1,'r':0}
df_train.capcolor.replace(capcolor_numeric, inplace=True)

bruises_numeric = {'t':1,'f':0}
df_train.bruises.replace(bruises_numeric, inplace=True)

gillspacing_numeric = {'c':1,'w':0}
df_train.gillspacing.replace(gillspacing_numeric, inplace=True)

gillsize_numeric = {'n':1,'b':0}
df_train.gillsize.replace(gillsize_numeric, inplace=True)

stalkshape_numeric = {'e':1,'t':0}
df_train.stalkshape.replace(stalkshape_numeric, inplace=True)

population_numeric = {'s':5,'n':4,'a':3,'v':2,'y':1,'c':0}
df_train.population.replace(population_numeric, inplace=True)

sporeprintcolor_numeric = {'k':8,'n':7,'u':6,'h':5,'w':4,'r':3,'o':2,'y':1,'b':0}
df_train.sporeprintcolor.replace(sporeprintcolor_numeric, inplace=True)

habitat_numeric = {'u':6,'g':5,'m':4,'d':3,'p':2,'w':1,'l':0}
df_train.habitat.replace(habitat_numeric, inplace=True)

ringtype_numeric = {'p':4,'e':3,'l':2,'f':1,'n':0}
df_train.ringtype.replace(ringtype_numeric, inplace=True)

ringnumber_numeric = {'o':2,'t':1,'n':0}
df_train.ringnumber.replace(ringnumber_numeric, inplace=True)

veilcolor_numeric = {'w':3,'n':2,'o':1,'y':0}
df_train.veilcolor.replace(veilcolor_numeric, inplace=True)

stalkcolorbelowring_numeric = {'w':8,'p':7,'g':6,'b':5,'n':4,'e':3,'y':2,'o':1,'c':0}
df_train.stalkcolorbelowring.replace(stalkcolorbelowring_numeric, inplace=True)

stalkcolorabovering_numeric = {'w':8,'g':7,'p':6,'n':5,'b':4,'e':3,'o':2,'c':1,'y':0}
df_train.stalkcolorabovering.replace(stalkcolorabovering_numeric, inplace=True)

stalksurfacebelowring_numeric = {'s':3,'f':2,'y':1,'k':0}
df_train.stalksurfacebelowring.replace(stalksurfacebelowring_numeric, inplace=True)

stalksurfaceabovering_numeric = {'s':3,'f':2,'k':1,'y':0}
df_train.stalksurfaceabovering.replace(stalksurfaceabovering_numeric, inplace=True)

stalkroot_numeric = {'e':4,'c':3,'b':2,'r':1,'?':0}
df_train.stalkroot.replace(stalkroot_numeric, inplace=True)

gillcolor_numeric = {'k':11,'n':10,'g':9,'p':8,'w':7,'h':6,'u':5,'e':4,'b':3,'r':2,'y':1,'o':0}
df_train.gillcolor.replace(gillcolor_numeric, inplace=True)

odor_numeric = {'p':8,'a':7,'l':6,'n':5,'f':4,'c':3,'y':2,'s':1,'m':0}
df_train.odor.replace(odor_numeric, inplace=True)

plt.figure(figsize=(12,9),dpi = 100)
sns.heatmap(df_train.corr(),vmax=.8,annot = True, square = True)
plt.show()

fig, ax = plt.subplots(4, 2, figsize = (15, 13))
sns.boxplot(x= df_train["gillsize"], ax = ax[0,0])
sns.distplot(df_train['gillsize'], ax = ax[0,1])
sns.boxplot(x= df_train["stalkcolorbelowring"], ax = ax[1,0])
sns.distplot(df_train['stalkcolorbelowring'], ax = ax[1,1])
sns.boxplot(x= df_train["veilcolor"], ax = ax[2,0])
sns.distplot(df_train['veilcolor'], ax = ax[2,1])
sns.boxplot(x= df_train["stalkroot"], ax = ax[3,0])
sns.distplot(df_train['stalkroot'], ax = ax[3,1])
plt.tight_layout()

sns.set(rc={'figure.figsize':(11.7,8.27)})
cData_attr = df_train.iloc[:, 0:7]
sns.pairplot(cData_attr, diag_kind='kde')

X = df_train.drop(['class','veiltype','gillattachment'], axis = 1)
Y = df_train["class"]
x_Data = X.values
y_Data = Y.values

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x_Data, y_Data, test_size = 0.2, random_state = 42)

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train,y_train)

model.score(X_test,y_test)

from sklearn.model_selection import cross_val_score
print(cross_val_score(GaussianNB(),X_train, y_train, cv=5))

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

pred = model.predict(X_train) 
accuracy_score(y_train, pred)

confusion_matrix(y_train, pred)

predicted_test = model.predict(X_test)
p=accuracy_score(y_test, predicted_test)

from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score

print(classification_report(y_test, predicted_test))

cma = confusion_matrix(y_test, predicted_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap=plt.cm.Blues, alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Random forest Classifier"""

from sklearn.ensemble import RandomForestClassifier as rf

clf_forest = rf(n_estimators=100, max_depth=10)
clf_forest.fit(X_train, y_train)

pred = clf_forest.predict(X_train)
accuracy_score(y_train, pred)

confusion_matrix(y_train, pred)

pred_test = clf_forest.predict(X_test)
q=accuracy_score(y_test, pred_test)

from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score

print(classification_report(y_test, pred_test))

cma = confusion_matrix(y_test, pred_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="coolwarm_r", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Decision Tree Classifier"""

from sklearn import tree

clf = tree.DecisionTreeClassifier()
 clf = clf.fit(X_train, y_train)

pred1 = clf.predict(X_train)
accuracy_score(y_train, pred1)

confusion_matrix(y_train, pred1)

pred1_test = clf.predict(X_test)
r=accuracy_score(y_test, pred1_test)

print(classification_report(y_test, pred1_test))

cma = confusion_matrix(y_test, pred1_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="coolwarm_r", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression  
clf1= LogisticRegression(random_state=0)  
clf1.fit(X_train, y_train)

pred_LR= clf1.predict(X_train)
accuracy_score(y_train, pred_LR)

confusion_matrix(y_train, pred_LR)

pred_LR_test = clf1.predict(X_test)
s=accuracy_score(y_test, pred_LR_test)

print(classification_report(y_test, pred_LR_test))

cma = confusion_matrix(y_test, pred_LR_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="coolwarm_r", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Neural networks"""

from sklearn.neural_network import MLPClassifier

clf2= MLPClassifier(solver='lbfgs', alpha=1e-5,
           hidden_layer_sizes=(5, 2), random_state=1)
clf2.fit(X_train, y_train)

pred_NN= clf2.predict(X_train)
accuracy_score(y_train, pred_NN)

confusion_matrix(y_train, pred_NN)

pred_NN_test = clf2.predict(X_test)
u=accuracy_score(y_test, pred_NN_test)

print(classification_report(y_test, pred_NN_test))

cma = confusion_matrix(y_test, pred_NN_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="prism", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# XGBOOST"""

import xgboost as xgb

xgb = xgb.XGBClassifier()
xgb.fit(X_train,y_train)

pred_XGB= xgb.predict(X_train)
accuracy_score(y_train, pred_XGB)

confusion_matrix(y_train, pred_XGB)

pred_XGB_test = xgb.predict(X_test)
v=accuracy_score(y_test, pred_XGB_test)

print(classification_report(y_test, pred_XGB_test))

cma = confusion_matrix(y_test, pred_XGB_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="prism", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Comparative predicting"""

import numpy as np
import matplotlib.pyplot as plt
# creating the dataset
data = {'NB':p, 'RF':q, 'DT':r,'LR':s,'NN':u,'XGB':v}
courses = list(data.keys())
values = list(data.values())
fig = plt.figure(figsize = (10, 6))
# creating the bar plot
plt.bar(courses, values, color ='crimson',
		width = 0.4)
plt.xlabel("Algorithms")
plt.ylabel("Accuracy")
plt.title("Comparitive analysis of algorithm on the basis of the acccuracy")
plt.show()

activities = ['NB', 'RF', 'DT', 'LR','NN','XGB'] 
# portion covered by each label
slices = [p,q,r,s,u,v]
 
# color for each label
colors = ['red', 'blue', 'green','yellow','black','crimson']
 
# plotting the pie chart
plt.pie(slices, labels = activities, colors=colors,
        startangle=90, shadow = True, explode = (0, 0, 0.1,0,0.1,0),
        radius = 1.2, autopct = '%1.1f%%')
 
# plotting legend
plt.legend()
 
# showing the plot
plt.show()

"""# Model saving"""

filename = 'naive_bayes.sav'
joblib.dump(model, filename)
filename1 = 'random_forest_Classifier.sav'
joblib.dump(clf_forest, filename1)
filename2 = 'decision_tree_classifier.sav'
joblib.dump(clf, filename2)
filename3 = 'logistic_regression.sav'
joblib.dump(clf1, filename3)
filename4 = 'neural_networks.sav'
joblib.dump(clf2, filename4)
filename5 = 'XGBOOST.sav'
joblib.dump(xgb, filename5)